-- Migration: Add flashcards for Chapters 8-14 (Distributed Systems)
-- Remote module IDs: Ch8=10, Ch9=11, Ch10=12, Ch11=13, Ch12=14, Ch13=15, Ch14=16

-- Chapter 8: Introduction and Overview (Distributed Systems) - module_id=10
INSERT INTO flashcards (module_id, front, back) VALUES
(10, 'What is the difference between concurrent and parallel execution?', 'Concurrent: both sequences are in progress, but only one executes at any moment (two queues, one coffee machine). Parallel: steps execute simultaneously by multiple processors (two queues, two coffee machines). Concurrent operations overlap in time; parallel ones run on multiple CPUs.'),
(10, 'What are consistency models in distributed systems?', 'Models that describe concurrent executions and establish the order in which operations can be executed and made visible to participants. They can constrain or relax the number of states the system can be in, defining execution histories precisely.'),
(10, 'What is fault tolerance?', 'The property describing whether a system can continue operating correctly in the presence of failures. Since failures are inevitable, fault-tolerant systems use redundancy and eliminate single points of failure.'),
(10, 'What are the Fallacies of Distributed Computing?', 'Peter Deutsch list (1994) of false assumptions: network is reliable, latency is zero, bandwidth is infinite, network is secure, topology does not change, there is one administrator, transport cost is zero, network is homogeneous.'),
(10, 'What is backpressure in distributed systems?', 'A strategy to handle producers publishing faster than consumers can process by slowing down producers. It prevents queues from growing unboundedly and helps maintain system stability under load.'),
(10, 'Why is assuming synchronized clocks dangerous in distributed systems?', 'Clocks drift between machines. Combined with latency-is-zero assumption, it causes problems in time-series processing. Unless using specialized high-precision sources, timestamps should not be used for synchronization or ordering.'),
(10, 'What is a fair-loss link?', 'A basic communication abstraction with three properties: (1) Fair loss - if sender keeps retransmitting infinitely, message eventually delivers; (2) Finite duplication - messages are not delivered infinitely many times; (3) No creation - link does not fabricate messages.'),
(10, 'What is a stubborn link?', 'A link abstraction where the sender keeps retransmitting messages indefinitely after timeout T. From the senders perspective, messages cannot get irrecoverably lost (assuming link stays intact), but this requires combining with acknowledgments for practicality.'),
(10, 'What is an idempotent operation?', 'An operation that can be executed multiple times yielding the same result without additional side effects. Example: server shutdown - first call initiates shutdown, subsequent calls have no effect. Important for safe retries in distributed systems.'),
(10, 'What is a perfect link?', 'A link abstraction providing: (1) Reliable delivery - messages from correct process A to correct process B eventually deliver; (2) No duplication - no message delivered more than once; (3) No creation - only delivers actually sent messages. Similar to TCP within a session.'),
(10, 'What is the Two Generals Problem?', 'A thought experiment showing agreement is impossible with asynchronous communication and link failures. Two generals must coordinate attack timing via messengers who can be captured. No matter how many ACKs are sent, neither can be certain the other will proceed.'),
(10, 'What is the FLP Impossibility?', 'Fischer, Lynch, Paterson proved that no completely asynchronous consensus algorithm can tolerate even a single process crash. Without timing assumptions, process failures cannot be reliably detected, so deterministic consensus in bounded time is impossible.'),
(10, 'What are the three properties of a correct consensus protocol?', '(1) Agreement - decision must be unanimous across all processes; (2) Validity - agreed value must be proposed by a participant (not predefined); (3) Termination - all processes must eventually reach a decision state.'),
(10, 'What is a synchronous vs asynchronous distributed system?', 'Synchronous: processes progress at comparable rates, transmission delays are bounded, message delivery cannot take arbitrarily long. Asynchronous: no timing assumptions, cannot reliably detect failures. Real systems are usually partially synchronous.'),
(10, 'What is a crash-stop failure model?', 'A failure model where a crashed process stops executing algorithm steps and sending messages, remaining in that state. Recovery is possible but the algorithm does not rely on it for correctness - process just participates in the next round.'),
(10, 'What is crash-recovery failure model?', 'A failure model where processes can stop executing but later recover and continue. Requires durable state and recovery protocol. Algorithms must consider all possible recovery states since recovering processes may continue from their last known step.'),
(10, 'What are omission faults?', 'Failures where a process skips algorithm steps, cannot execute them visibly, or cannot send/receive messages. Captures network partitions, slow nodes, lost messages. A crash can be simulated by completely omitting all messages to/from a process.'),
(10, 'What are Byzantine (arbitrary) faults?', 'Failures where a process executes algorithm steps but contradicts the algorithm (e.g., deciding on values no one proposed). Can be from bugs, version mismatches, or malicious actors. Hardest to handle; used in aerospace systems and cryptocurrencies.'),
(10, 'What is a network partition?', 'When two or more servers cannot communicate with each other. Can isolate groups that proceed independently, potentially producing conflicting results. Links can fail asymmetrically (A can reach B but not vice versa).'),
(10, 'How do backoff and jitter help with cascading failures?', 'Backoff: instead of immediate retry, clients wait increasing time periods between requests to avoid amplifying problems. Jitter: adds random delays to backoff to prevent different clients from retrying simultaneously after backoff period ends.');

-- Chapter 9: Failure Detection - module_id=11
INSERT INTO flashcards (module_id, front, back) VALUES
(11, 'What is a failure detector?', 'A local subsystem responsible for identifying failed or unreachable processes to exclude them from the algorithm. It guarantees liveness (detection must occur) while preserving safety (only actually failed processes are marked as failed).'),
(11, 'What are liveness and safety in distributed algorithms?', 'Liveness: specific intended events must occur (e.g., failure detector must detect failures). Safety: unintended events will not occur (e.g., a process marked dead must actually be dead). There is often a trade-off between them.'),
(11, 'What is the completeness property of failure detectors?', 'Every nonfaulty member should eventually notice the process failure, and the algorithm should be able to make progress and reach its final result. It ensures failures do not go undetected indefinitely.'),
(11, 'What is the trade-off between efficiency and accuracy in failure detection?', 'A more efficient algorithm (faster detection) is usually less accurate (more false positives). A more accurate algorithm takes longer to confirm failures. It is provably impossible to be both perfectly accurate and efficient.'),
(11, 'What is the difference between pings and heartbeats?', 'Pings: a process sends messages to remote processes and expects responses within a time period. Heartbeats: a process actively notifies peers it is running by sending periodic messages. Both achieve similar results.'),
(11, 'What is the timeout-free Heartbeat failure detector?', 'An algorithm that counts heartbeats without using timeouts, operating under asynchronous assumptions. Processes maintain counters for neighbors and propagate heartbeat messages with paths showing which processes they traveled through.'),
(11, 'What are outsourced heartbeats (SWIM protocol)?', 'When P1 cannot reach P2 directly, it asks random members (P3, P4) to send heartbeats to P2. If P2 responds to them, they forward ACKs to P1. This accounts for both direct and indirect reachability, improving accuracy.'),
(11, 'How does the phi-accrual failure detector work?', 'Instead of binary up/down, it uses a continuous scale measuring crash probability (φ). It maintains a sliding window of heartbeat arrival times, estimates arrival distribution, and computes suspicion level that adapts to network conditions.'),
(11, 'What are the three subsystems of a phi-accrual failure detector?', '(1) Monitoring: collecting liveness info via pings/heartbeats. (2) Interpretation: deciding if process should be marked suspected. (3) Action: callback executed when process is marked suspected. Used in Cassandra and Akka.'),
(11, 'How does gossip-style failure detection work?', 'Each member maintains a list of other members with heartbeat counters and timestamps. Members periodically increment their counter and gossip their list to random neighbors. Nodes merge received lists and mark nodes as failed if counters are stale.'),
(11, 'What is FUSE failure detection?', 'Failure notification service that converts individual process failures to group failures. If a member cannot respond to pings (crash/partition), the pinger also stops responding. Failure propagates through quiescence (absence of communication).'),
(11, 'Why can failure detectors make infinite mistakes and still be useful?', 'Chandra and Toueg proved consensus is possible even with imperfect failure detectors. The key is eventual accuracy - the detector eventually stops making mistakes. Temporary false positives can be tolerated as long as the system eventually converges.'),
(11, 'What is the relationship between failure detection and consensus?', 'FLP proves consensus is impossible in asynchronous systems. Failure detectors augment the model by making timing assumptions, enabling consensus algorithms. They are a prerequisite for many consensus and atomic broadcast algorithms.'),
(11, 'How does gossip failure detection handle link failures?', 'If there is a link failure between two hosts, heartbeats can still propagate through other processes. The aggregated view from multiple nodes makes the decision reliable, avoiding false positives from temporary link issues.'),
(11, 'What are the downsides of simple ping/timeout failure detection?', '(1) Precision relies on careful selection of ping frequency and timeout values. (2) Does not capture process visibility from perspectives of other processes. (3) Network delays can cause false positives.');

-- Chapter 10: Leader Election - module_id=12
INSERT INTO flashcards (module_id, front, back) VALUES
(12, 'Why do distributed systems use leader election?', 'To reduce synchronization overhead and message round-trips. A leader coordinates algorithm steps, avoiding peer-to-peer coordination. Leaders hold global state, collect messages, and disseminate them, reducing the number of messages needed.'),
(12, 'What are the liveness and safety properties of leader election?', 'Liveness: most of the time there will be a leader, and election will eventually complete. Safety: at most one leader at a time (no split brain). In practice, many algorithms sacrifice safety for liveness, resolving conflicts later.'),
(12, 'What is the difference between leader election and distributed locking?', 'In locking, other processes do not need to know who holds the lock, only that it will be released. In leader election, the leader has special properties and must be known to all participants - the leader must notify peers of its role.'),
(12, 'How does the bully algorithm work?', 'Each process has a unique rank. During election: (1) Send election messages to higher-ranked processes. (2) Wait for responses; if none, proceed. (3) Assume leadership and notify lower-ranked processes. Highest-ranked process wins.'),
(12, 'What is the split brain problem in leader election?', 'When network partitions cause nodes to split into independent subsets, each subset may elect its own leader. Multiple leaders are unaware of each other, potentially causing inconsistent operations. Bully algorithm is vulnerable to this.'),
(12, 'What is the instability problem with the bully algorithm?', 'Strong preference for high-ranked nodes becomes problematic if they are unstable. An unstable high-ranked node repeatedly wins election, crashes, wins reelection, crashes again - causing permanent reelection state.'),
(12, 'How does next-in-line failover improve the bully algorithm?', 'Each elected leader provides a list of failover nodes. When failure is detected, the detector contacts the highest-ranked alternative from the list. If that alternative is up, it becomes leader without a full election round.'),
(12, 'What is the candidate/ordinary optimization?', 'Nodes are split into candidate and ordinary sets. Only candidates can become leaders. Ordinary processes initiate elections by contacting candidates, collecting responses, picking highest-ranked alive candidate, and notifying all nodes.'),
(12, 'How does the invitation algorithm work?', 'Each process starts as leader of its own single-member group. Leaders invite other processes to join. When two leaders meet, groups merge. The algorithm allows multiple leaders by design since each group has one.'),
(12, 'How does the ring algorithm elect a leader?', 'Nodes form a ring, knowing their successors. Election message traverses the ring; each node adds itself to a live set. When message returns to initiator, highest-ranked from live set becomes leader. A second round broadcasts the result.'),
(12, 'Why is leader election related to consensus?', 'To elect a leader, processes must reach consensus on its identity. If you can solve consensus for leader identity, you can solve it for anything. Many consensus algorithms (Multi-Paxos, Raft) use leaders and have their own election mechanisms.'),
(12, 'What is stable leader election?', 'An algorithm combining leader election with failure detection using timeout-based detection and election rounds with unique stable leaders. Guarantees the leader retains its position as long as it does not crash and remains accessible.'),
(12, 'How do consensus algorithms handle multiple leaders?', 'They allow temporary multiple leaders and resolve conflicts quickly. Multi-Paxos: only one proposer can proceed, conflicts resolved by collecting a second quorum. Raft: leader discovers out-of-date term and updates. Safety is maintained via conflict resolution.'),
(12, 'Why can a leader become a bottleneck?', 'All coordination goes through the single leader process. Solution: partition data into non-intersecting replica sets, each with its own leader. Systems like Spanner use per-partition leaders to distribute load.'),
(12, 'How does tiebreaker delay prevent simultaneous elections?', 'In candidate/ordinary algorithm, each process has a process-specific delay δ before initiating election. Higher priority nodes have lower δ. This allows one node to start election before others, reducing message conflicts.');

-- Chapter 11: Replication and Consistency - module_id=13
INSERT INTO flashcards (module_id, front, back) VALUES
(13, 'Why is data replication important?', 'Introduces redundancy by maintaining multiple copies of data. Increases availability (failover when machines fail), improves latency (data closer to clients), and enables fault tolerance. However, keeping copies in sync is as hard as consensus.'),
(13, 'What does the CAP theorem state?', 'In a distributed system, you cannot simultaneously guarantee Consistency (linearizability), Availability (every request gets a response), and Partition tolerance. During network partitions, you must choose between consistency (CP) or availability (AP).'),
(13, 'What is the difference between CP and AP systems?', 'CP systems (like consensus algorithms) prefer failing requests over serving inconsistent data - always consistent but may be unavailable during partitions. AP systems (like eventually consistent DBs) serve requests even with potentially inconsistent values during partitions.'),
(13, 'What is PACELEC?', 'Extension of CAP: In Partition cases, choose between Availability and Consistency (PAC). Else (E), even when running normally, choose between Latency and Consistency. Recognizes that consistency/latency trade-offs exist even without failures.'),
(13, 'What is harvest vs yield?', 'Harvest: how complete query results are (99 of 100 rows vs failing completely). Yield: ratio of successful requests to total attempts. These metrics allow relaxed trade-offs rather than binary consistency/availability choices.'),
(13, 'What is a linearizable (atomic) register?', 'Guarantees linearizability: every write has a single moment before which reads return old value, after which reads return new value. No partial writes visible. Simplifies reasoning but requires coordination and is expensive to implement.'),
(13, 'What is a linearization point?', 'The moment at which an operations effects become visible to all processes. Before this point, old value is visible; after, new value is visible. Operations appear instantaneous even though they take time.'),
(13, 'What is sequential consistency?', 'Operations can be ordered as if executed sequentially, preserving each processs local order. Unlike linearizability, has no global time bounds - operations can become visible after completion. All processes see same order, but reads can be arbitrarily stale.'),
(13, 'How does sequential consistency differ from linearizability?', 'Both require global operation order, but linearizability requires local and global order to be consistent (respects real-time). Sequential consistency only requires same-origin writes to be ordered. Also, linearizable schedules compose; sequential ones do not.'),
(13, 'What is causal consistency?', 'All processes see causally related operations in the same order. Concurrent writes with no causal relationship can be observed in different orders by different processes. Implemented using logical clocks and metadata about operation dependencies.'),
(13, 'What are vector clocks used for?', 'Establishing partial order between events, detecting and resolving divergence between event chains. Each process maintains a vector of logical clocks (one per process), incrementing on events and merging on message receipt.'),
(13, 'What are the four session guarantees in causal consistency?', '(1) Monotonic reads: subsequent reads see values at least as recent. (2) Monotonic writes: same-client writes appear in order. (3) Read-your-writes: reads see own prior writes. (4) Writes-follow-reads: writes ordered after reads they depend on.'),
(13, 'What is eventual consistency?', 'If no new writes occur, all replicas eventually converge to the same value. Provides no ordering guarantees during updates - replicas can diverge temporarily. Good for availability and latency but requires conflict resolution strategies.'),
(13, 'What is tunable consistency?', 'Systems allowing per-operation consistency level configuration. Example: Cassandra lets you choose how many replicas must acknowledge reads/writes. Trade-off flexibility but requires understanding implications of each level.'),
(13, 'What is strong eventual consistency?', 'Eventual consistency plus guarantee that replicas receiving same updates will be in the same state (no conflicts). Uses CRDTs (Conflict-free Replicated Data Types) that mathematically guarantee convergence regardless of operation order.');

-- Chapter 12: Anti-Entropy and Dissemination - module_id=14
INSERT INTO flashcards (module_id, front, back) VALUES
(14, 'What are the three main approaches for propagating cluster-wide updates?', '(1) Notification broadcast - one process broadcasts to all others. (2) Periodic peer-to-peer anti-entropy - pairs exchange and reconcile messages. (3) Cooperative gossip - message recipients become broadcasters to spread information faster and more reliably.'),
(14, 'What is entropy in distributed systems?', 'A measure of disorder representing the degree of state divergence between nodes. Anti-entropy mechanisms aim to minimize this divergence and bring nodes back into sync when primary delivery mechanisms fail.'),
(14, 'What is read repair?', 'A foreground anti-entropy mechanism where the coordinator detects divergence during reads by comparing replica responses. If responses differ, the coordinator sends missing updates to lagging replicas. Can be blocking (wait for repair) or async.'),
(14, 'What are digest reads?', 'Instead of full reads from all replicas, coordinator issues one full read and digest (hash) requests to others. If digests match, replicas are in sync. If not, coordinator must issue full reads to mismatched replicas, compare, and repair.'),
(14, 'What is hinted handoff?', 'A write-side anti-entropy mechanism. If a target node fails to acknowledge a write, the coordinator stores a hint that is replayed to the target node when it recovers. Hints are not counted toward replication factor since they are not readable.'),
(14, 'What are sloppy quorums?', 'During replica failures, writes use additional healthy nodes outside the original replica set. Data written to substitute nodes has hints in metadata to forward to original replicas when they recover. Improves availability but can sacrifice consistency.'),
(14, 'How do Merkle trees help with anti-entropy?', 'Build a tree of hashes from data record ranges. Compare root hashes between replicas - if they match, replicas are in sync. If not, recursively compare subtrees to locate exactly which ranges have diverged, then repair only those.'),
(14, 'What is the trade-off with Merkle trees?', 'Any data change requires recomputing the entire subtree up to root. Also, trade-off between tree size (message size for exchange) and precision (how exact the divergent ranges are). Larger trees = more precise but more overhead.'),
(14, 'What are bitmap version vectors?', 'Each node keeps per-peer logs of operations. Operations are represented as dots (sequence_number, node_id). During anti-entropy, nodes exchange logical clocks, identify gaps (missing dots), and replicate associated data records.'),
(14, 'How do gossip protocols work?', 'Processes periodically select f random peers (fanout) and exchange hot information. Recipients become infective and pass on information. Like disease spreading through population - achieves broadcast reach with anti-entropy reliability.'),
(14, 'What are the three states in gossip protocols?', '(1) Susceptible - has not received the update. (2) Infective - has received update and actively disseminating to random peers. (3) Removed - no longer propagating after being certain the update has spread sufficiently.'),
(14, 'What is redundancy in gossip protocols?', 'The metric capturing overhead from repeated message delivery. Because peers are selected randomly, overlap occurs and messages get delivered multiple times. Redundancy is crucial to gossip reliability but has cost.'),
(14, 'How do gossip protocols achieve convergence?', 'Either probabilistically (each process computes probability of stopping propagation) or using thresholds (count duplicate receipts, stop when too high). Both must consider cluster size and fanout. System converges when gossip stops.'),
(14, 'What is convergent consistency in gossip?', 'Nodes have higher probability of agreeing on events that occurred further in the past. Recent events may not have propagated everywhere yet, but older events have had more time to spread through the system.'),
(14, 'Why are gossip protocols robust?', 'Random peer selection means messages can be delivered through different paths if some links fail. System adapts to network partitions since indirect connections can still propagate messages. No single point of failure.');

-- Chapter 13: Distributed Transactions - module_id=15
INSERT INTO flashcards (module_id, front, back) VALUES
(15, 'What is atomic commitment?', 'A class of algorithms ensuring that a transaction commits on all nodes or none. Does not allow disagreements - if even one participant votes against, transaction aborts. Failed processes must reach the same conclusion as the rest. Does not work with Byzantine failures.'),
(15, 'What is two-phase commit (2PC)?', 'An atomic commitment protocol with two phases: (1) Prepare - coordinator proposes transaction, cohorts vote yes/no. (2) Commit/Abort - if all vote yes, coordinator sends Commit; otherwise Abort. All decisions are logged for recovery.'),
(15, 'What happens if a cohort fails during 2PC prepare phase?', 'The coordinator cannot proceed with commit since it requires all positive votes. The coordinator will abort the transaction. This negatively impacts availability - failure of a single node prevents the transaction.'),
(15, 'What happens if a cohort fails after voting yes in 2PC?', 'When it recovers, it must learn the final outcome before serving requests - the coordinator might have aborted due to other cohorts decisions. The cohort reads from coordinator decision log or peer transaction logs.'),
(15, 'Why is 2PC called a blocking protocol?', 'If the coordinator fails after collecting votes but before broadcasting results, cohorts are stuck in an undecided state. They cannot determine the final decision if the coordinator never recovers. Must wait or elect new coordinator to re-collect votes.'),
(15, 'What is three-phase commit (3PC)?', 'Adds a Prepare phase between voting and commit to allow cohorts to proceed if coordinator fails. Three phases: (1) Propose - collect votes, (2) Prepare - notify cohorts of vote results, (3) Commit - finalize transaction. Assumes synchronous model.'),
(15, 'How does 3PC handle coordinator failure?', 'Cohorts can timeout and make deterministic decisions based on their state. If not yet in prepared state, abort. If all moved to prepared state, commit. This avoids the blocking problem of 2PC but has higher message overhead.'),
(15, 'What is the split-brain problem in 3PC?', 'During network partition: some nodes reach prepared state and commit after timeout, while others cannot communicate and abort after timeout. This leaves participants in contradictory states - the reason 3PC is rarely used in practice.'),
(15, 'What is a transaction manager?', 'A database subsystem responsible for scheduling, coordinating, executing, and tracking transactions. In distributed systems, ensures node-local visibility guarantees are consistent with distributed atomic operations.'),
(15, 'What is Calvin?', 'A deterministic transaction processing system where replicas agree on execution order before acquiring locks. Because all nodes execute same order deterministically, node failures do not cause aborts - state can be recovered from peers.'),
(15, 'What is Spanner?', 'Google distributed database using 2PC over Paxos groups (not individual nodes) for availability. Uses TrueTime API with atomic clocks for external consistency. Performs reads at timestamps to avoid blocking for read-only transactions.'),
(15, 'How does Spanner achieve external consistency?', 'Uses TrueTime API providing global synchronized time with bounded uncertainty. Transactions are assigned timestamps; reads happen at timestamps. Combined with 2PC over Paxos groups, provides strong consistency across datacenters.'),
(15, 'What is database partitioning?', 'Splitting data across multiple nodes so each partition handles a subset. Single-partition transactions are simpler. Multi-partition transactions require distributed coordination (2PC/3PC). Partitioning improves scalability but adds coordination complexity.'),
(15, 'Why do some systems run 2PC over Paxos groups?', 'Individual node failures block 2PC. Running 2PC over consensus groups (like Spanner does) means the group can make progress even if individual nodes fail, improving availability without sacrificing atomicity.'),
(15, 'What are the trade-offs between 2PC and 3PC?', '2PC: simpler, lower message overhead, but blocking on coordinator failure. 3PC: non-blocking, but higher message overhead, assumes synchronous model, vulnerable to split-brain during partitions. Most systems use 2PC with recovery mechanisms.'),
(15, 'What is serializability in distributed transactions?', 'A correctness criterion where the outcome of concurrent transaction execution is equivalent to some serial (one-at-a-time) execution. A history is serializable if it has the same dependency graph as some sequential execution of those transactions.');

-- Chapter 14: Consensus - module_id=16
INSERT INTO flashcards (module_id, front, back) VALUES
(16, 'What are the three properties of consensus algorithms?', '(1) Agreement - decision value is same for all correct processes. (2) Validity - decided value was proposed by some process (not predetermined). (3) Termination - all correct processes eventually reach a decision.'),
(16, 'What is atomic broadcast (total order multicast)?', 'A broadcast that guarantees both reliable delivery and total order. All non-failed processes deliver the same set of messages in the same order. Equivalent to consensus in asynchronous systems with crash failures.'),
(16, 'What is virtual synchrony?', 'A group communication framework delivering totally ordered messages to dynamic process groups. Messages are associated with group identity; if the group view changes (member joins/leaves/fails), messages from the old view cannot be delivered in the new view.'),
(16, 'What are the three phases of ZAB (Zookeeper Atomic Broadcast)?', '(1) Discovery - prospective leader proposes new epoch, learns latest transactions. (2) Synchronization - leader establishes itself, brings followers up to date. (3) Broadcast - leader receives client messages, establishes order, broadcasts to followers.'),
(16, 'What is an epoch in ZAB?', 'A timeline period with a unique monotonically increasing number. During any epoch, there can be only one leader. Epochs ensure leader uniqueness and help resolve conflicts from previous leaders failures.'),
(16, 'What are the three roles in Paxos?', '(1) Proposers - receive client values, create proposals, collect votes. (2) Acceptors - vote to accept/reject proposals (quorum required). (3) Learners - store outcomes of accepted proposals (replicas). Any process can take any role.'),
(16, 'What are the two phases of basic Paxos?', '(1) Propose/voting phase - proposer sends Prepare(n) to acceptors, collects promises. (2) Replication phase - proposer sends Accept!(n,v) to acceptors with value v. Acceptors notify learners of accepted values.'),
(16, 'What does an acceptor promise in Paxos prepare phase?', 'When accepting Prepare(n): (1) Will not accept proposals with lower sequence numbers. (2) If already accepted a proposal, responds with that proposals number and value. (3) If already promised to higher number, rejects.'),
(16, 'Why do Paxos acceptors respond with previously accepted values?', 'To preserve agreement. Once consensus is reached on a value, future proposers must decide on the same value. If an acceptor already accepted v, new proposers learn about v and must use it instead of their own value.'),
(16, 'What is a quorum in Paxos?', 'Minimum votes required to proceed - typically a majority. Any two majorities overlap by at least one participant who acts as arbiter ensuring correctness. Allows progress with f failures if you have 2f+1 total processes.'),
(16, 'What is Multi-Paxos?', 'Optimization where a stable leader skips the propose phase for subsequent values. After establishing leadership once, the leader can directly send Accept messages for multiple values, reducing round-trips from 2 to 1 per value.'),
(16, 'What is Raft?', 'A consensus algorithm designed for understandability. Uses strong leader model - only leader handles client requests. Log replication is one-directional (leader to followers). Uses randomized election timeouts to avoid split votes.'),
(16, 'What are the three states in Raft?', '(1) Follower - passive, responds to leader/candidate requests. (2) Candidate - requests votes to become leader. (3) Leader - handles all client requests, replicates log entries to followers.'),
(16, 'What is a term in Raft?', 'A logical clock dividing time into periods, each with at most one leader. Terms are numbered consecutively. If a node sees a higher term, it updates its term. Stale term requests are rejected.'),
(16, 'How does Raft leader election work?', 'Follower times out waiting for heartbeat, becomes candidate, increments term, votes for itself, requests votes from others. Wins if gets majority. Uses randomized election timeout (150-300ms) to prevent split votes.');
